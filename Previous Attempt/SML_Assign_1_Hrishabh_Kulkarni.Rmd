---
author: "Hrishabh Kulkarni"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1. Binary Classification: Predicting Marijuana Use (MRJFLAG)
## 2. Multi-Class Classification: Predicting Alcohol Frequency (AlcoholFreq)
## 3. Regression: Predicting Cigarette Days (CigaretteUsageDays)

```{r}
library(rpart)
library(randomForest)
library(dplyr)
library(gbm)
library(caret)
library(pROC)
library(pdp)
library(rpart.plot)     # Using it for plotting decision trees
library(tree)
```

```{r}
rm(list = ls())   
load("youth_data.Rdata")
ls()
```

```{r}
head(df, 5)
```

```{r}
colnames(df)
```

## 1. Binary Classification: Predicting Marijuana Use (MRJFLAG)

# Data Prep

```{r}
target_binary <- "MarijuanaUse"
df <- df %>% rename(MarijuanaUse = MRJFLAG)
```

```{r}
predictors_binary <- c(
  "ParentalDisapproval",
  "SchoolPunishment",  
  "GroupFights",         
  "Friends_Use_MJ",     
  "FriendsOfferedMJ",   
  "ParentsUseMJ"      
)
```

```{r}
df <- df %>% rename(
  FriendsUseMJ = FRDMEVR2,
  FriendsOfferedMJ = YFLTMRJ2,
  ParentsUseMJ = PRMJEVR2,
  ParentalDisapproval = PRMJMO,
  SchoolPunishment = STNDSMJ,
  GroupFights = YOGRPFT2
)
```


```{r}
# 1 = Used & 0 = Not Used
df$MarijuanaUse <- ifelse(df$MarijuanaUse == 1, 1, 0)
```


```{r}
predictors_binary <- c("FriendsUseMJ", "FriendsOfferedMJ", "ParentsUseMJ", "ParentalDisapproval", "SchoolPunishment", "GroupFights")
target_binary <- "MarijuanaUse"
```


```{r}
clean_df <- na.omit(df[, c(target_binary, predictors_binary)])


clean_df[[target_binary]] <- as.factor(clean_df[[target_binary]])
```

Above, I am converting target to factor, removes rows with NA's in the columns used for modeling.


```{r}
set.seed(1)
train <- createDataPartition(clean_df[[target_binary]], p = 0.7, list = FALSE)
data.train <- clean_df[train, ]
data.test <- clean_df[-train, ]
```

Used createDataPartition to split the data into training and testing sets.
It was the best way which was ensuring that the target variable is balanced in both sets.
Reference: https://www.rdocumentation.org/packages/caret/versions/6.0-94/topics/createDataPartition


# Decision Tree (With and Without Pruning)

```{r}
# Fitting unpruned tree
tree_unpruned <- rpart(
  paste(target_binary, "~", paste(predictors_binary, collapse = "+")),
  data = data.train,
  method = "class",
  control = rpart.control(cp = 0, minsplit = 10)
)
```

```{r}
summary(tree_unpruned)
```
Made use of rpart library as it was easy to implement and I was facing continued issues with basic r code and cv.tree code.
rpart.control -> sets complexity parameter (cp) to 0 - means no pruning.
minsplit -> 10, means a node must have at least 10 observations to be split.
Reference: https://www.rdocumentation.org/packages/rpart/versions/4.1.24/topics/rpart

Unpruned Tree:
Deep and complex with many splits.
FriendsOfferedMJ and ParentalDisapproval are primary splits.
Accuracy: 87.99%.

```{r}
# Pruning tree
pruned_tree <- prune(tree_unpruned, cp = 0.01)
```

```{r}
summary(pruned_tree)
```

Pruned Tree (CP=0.01):
Simplified structure with fewer splits.
Accuracy: Similar to unpruned, but more interpretable and easy to understand and convey result.

```{r}
rpart.plot(tree_unpruned, main = "Unpruned Tree")
rpart.plot(pruned_tree, main = "Pruned Tree (CP=0.01)")
```

Using rpart.plot for better visualization of decision trees.
Reference: https://www.rdocumentation.org/packages/rpart.plot/versions/3.1.2/topics/rpart.plot

```{r}
plot(tree_unpruned, main="Unpruned Tree")
text(tree_unpruned, cex=0.5)

plot(pruned_tree, main="Pruned Tree (CP=0.01)")
text(pruned_tree, cex=1.5)
```
cex helped me to adjust the text size in the plot, so utilizing it for better visualization.

```{r}
tree_preds <- predict(tree_unpruned, data.test, type = "class")
```

```{r}
confusionMatrix(tree_preds, as.factor(data.test$MarijuanaUse))
```

Pruning simplifies the tree but may sacrifice slight or no accuracy.


# Bagging

```{r}
bag_binary <- randomForest(
  x = data.train[, predictors_binary],
  y = as.factor(data.train[, target_binary]),
  mtry = 6, # p -> bagging 
  ntree = 500,
  importance = TRUE
)
```


```{r}
varImpPlot(bag_binary, col = "blue", main = "Variable Importance (Alcohol Frequency)")
```

```{r}
bag_preds <- predict(bag_binary, data.test[, predictors_binary])
```


```{r}
confusionMatrix(bag_preds, as.factor(data.test$MarijuanaUse))
```

Bagging (mtry=6)
Variable Importance: SchoolPunishment and FriendsUseMJ most influential.

Performance:
Accuracy: 87.99% (same as decision tree).
OOB Error: 12.44% which tells moderate misclassification rate.


# Random Forest

```{r}
rf_binary <- randomForest(
  x = data.train[, predictors_binary],
  y = as.factor(data.train[, target_binary]),
  mtry = sqrt(6),  # I am considering square root of p for classification
  ntree = 500,
  importance = TRUE
)
```

```{r}
print(rf_binary)
```

```{r}
varImpPlot(rf_binary, col = "orange", main = "Variable Importance (Alcohol Frequency)")
```

```{r}
rf_preds <- predict(rf_binary, data.test[, predictors_binary])
```


```{r}
confusionMatrix(rf_preds, as.factor(data.test$MarijuanaUse))
```

Random Forest (mtry=sqrt(6) almost equals 2)
Performance:
Accuracy: 87.86% 
slightly lower than bagging.
45.38% (struggled with identifying marijuana users.

Variable Importance:
Similar to bagging but with slight difference..


```{r}
# Implemented Test accuracy for different mtry values as performed in worksheet
test_acc <- c()
for (p in c(1, 3, 5, 7, 10)) {
  rf.temp <- randomForest(
    x = data.train[, predictors_binary],
    y = as.factor(data.train[, target_binary]),
    mtry = sqrt(p), 
    ntree = 500
  )
  pred <- predict(rf.temp, newdata = data.test[, predictors_binary])
  acc <- mean(pred == data.test$MarijuanaUse)
  test_acc <- c(test_acc, acc)
}

plot(c(1, 3, 5, 7, 10), test_acc, type = "b", pch = 19,
     xlab = "mtry Value", ylab = "Test Accuracy",
     main = "Test Accuracy vs mtry for MarijuanaUse RF")
```

# Boosting

```{r}
table(data.train[[target_binary]])
```

```{r}
data.train[[target_binary]] <- as.integer(as.factor(data.train[[target_binary]])) - 1
```


```{r}
boost_binary <- gbm(
  formula = as.formula(paste(target_binary, "~", paste(predictors_binary, collapse = "+"))),
  data = data.train,
  distribution = "bernoulli",  # binary classification = bernoulli
  n.trees = 1000,
  interaction.depth = 4,
  shrinkage = 0.01,
  verbose = FALSE
)
```

```{r}
summary(boost_binary)
```

```{r}
gbm.perf(boost_binary)
```
350 iteration seems best.
```{r}
### ROC Curve (Boosting)

```{r}
boost_probs <- predict(boost_binary, data.test, n.trees = 1000, type = "response")
boost_preds <- ifelse(boost_probs > 0.5, 1, 0)
```

```{r}
roc_curve <- roc(data.test$MarijuanaUse, boost_probs)
plot(roc_curve, main = "ROC Curve (Boosting)", col = "brown")
```

Interpretation:
AUC > 0.9 indicates excellent model performance.


```{r}
confusionMatrix(as.factor(boost_preds), as.factor(data.test$MarijuanaUse))
```
Boosting (GBM)
Best Performance:
AUC > 0.9 -> accurate divisions.

Accuracy: 87.86% 
similar to RF but better class separation.

Top Predictor:
SchoolPunishment with 33.15% relative influence.

ROC Curve:
Strong true positive rate (sensitivity) vs. false positive rate.


Results Summary

Key Insight: 
Top Predictors:
School Punishment, Friends Use MJ, Friends Offered MJ (highest importance in boosting).
Parental disapproval and peer influence significantly impact marijuana use.

Model Performance Comparison:
Model	Accuracy	Sensitivity
Decision Tree	87.99%	95.48%
Bagging	87.99%	95.52%
Random Forest	87.86%	95.68%
Boosting	87.86%	95.29%	

Key Insight: Boosting outperformed others with the highest AUC, while tree-based methods had comparable accuracy but lower specification as it struggled with minority class "1".



## 2. Multi-Class Classification: Predicting Alcohol Frequency (AlcoholFreq)

# Data Prep

```{r}
target_multi <- "AlcoholFreq"
df <- df %>% rename(AlcoholFreq = IRALCFY)
```

```{r}
predictors_multi <- c(
  "Grades", 
  "PhysicalFights",  
  "Gender",      
  "Race",       
  "Income",     
  "SchoolSafety" 
)
```

```{r}
df <- df %>% rename(
  Gender = IRSEX,
  Race = NEWRACE2,
  Income = INCOME,
  Grades = AVGGRADE,
  SchoolSafety = SCHFELT,
  PhysicalFights = YOFIGHT2
)
```

```{r}
df$AlcoholFreq <- as.factor(df$AlcoholFreq)
```
Helps lock the factor levels for target variable, ensuring consistent levels across training and testing sets. Implemented several times throughout the code.
Refernce: https://stackoverflow.com/questions/39543606/r-getting-column-of-dataframe-from-string/39543627#39543627

```{r}
predictors_multi <- c("Gender", "Race", "Income", "Grades", "SchoolSafety", "PhysicalFights")
target_multi <- "AlcoholFreq"
```

```{r}
clean_df <- na.omit(df[, c(target_multi, predictors_multi)])


clean_df[[target_multi]] <- as.factor(clean_df[[target_multi]])
```


```{r}
set.seed(1)
train <- createDataPartition(clean_df[[target_multi]], p = 0.7, list = FALSE)
data.train <- clean_df[train, ]
data.test <- clean_df[-train, ]
```


# Decision Tree

```{r}
#By default a Pruned tree as well as considering cp as 0.01
tree_multi <- rpart(
  paste(target_multi, "~", paste(predictors_multi, collapse = "+")),
  data = data.train,
  method = "class",
  control = rpart.control(cp = 0.01)
)
```

```{r}
plot(tree_unpruned, uniform = TRUE, margin = 0.1)
text(tree_unpruned, use.n = TRUE, cex = 0.7)
```


```{r}
tree_preds <- predict(tree_multi, data.test, type = "class")
```


```{r}
confusionMatrix(tree_preds, data.test$AlcoholFreq)
```
Decision Tree (Pruned, CP=0.01)
Performance:

Accuracy: 77.62% (driven by dominant class "991").
Issue: Severe class imbalance (e.g., class 991 = 77.6%. This seems to because the data is not cleaned properly and sp not balanced.
Takeaway: Handle the class class 991 to know actual model performance.


# Bagging

```{r}
# Written this line as the unused factors were creating an issue so found a way to drop unused factor levels.
data.train[[target_multi]] <- droplevels(data.train[[target_multi]])

bag_multi <- randomForest(
  x = data.train[, predictors_multi],
  y = data.train[[target_multi]],
   mtry = 6,
  ntree = 500,
  importance = TRUE
)
```

```{r}
varImpPlot(bag_multi, col = "darkgreen", main = "Variable Importance (Alcohol Frequency)")
```

```{r}
print(bag_multi)
```

```{r}
bag_preds <- predict(bag_multi, data.test)
```


```{r}
# Again, this line helps maintaining the levels while&after predictions
bag_preds <- factor(bag_preds, levels = levels(data.test$AlcoholFreq))
```

```{r}
confusionMatrix(bag_preds, data.test$AlcoholFreq)
```

Bagging (mtry=6)
Performance:
Accuracy: 77.03% (no improvement over tree).
OOB Error: 24.35%.
Variable Importance: Income, Race, and Grades most influential.


# Random Forest

```{r}
rf_multi <- randomForest(
  x = data.train[, predictors_multi],
  y = data.train$AlcoholFreq,
  mtry = sqrt(6),
  ntree = 500,
  importance = TRUE
)
```


```{r}
varImpPlot(rf_multi, col = "darkred", main = "Variable Importance (Alcohol Frequency)")
```

```{r}
rf_preds <- predict(rf_multi, data.test)
```

```{r}
rf_preds <- factor(rf_preds, levels = levels(data.test$AlcoholFreq))
```

```{r}
confusionMatrix(rf_preds, data.test$AlcoholFreq)
```

Random Forest (mtry= sqrt(6) = almost 2)
Performance:
Accuracy: 77.62% (same as decision tree).
No meaningful improvement due to extreme imbalance.


Result Summary:
Top Predictors: Income, Race, Grades (most influential in RF/bagging).
School safety and gender had moderate effects.

Model Performance Comparison:
Model	Accuracy
Decision Tree	77.62%
Bagging	77.03%
Random Forest	77.62%

Key Issues: High class imbalance (class 991). Class Imbalance issue.
Takeaway: class 991 should be handled to improve model performance.

Recommendation: Address imbalance (e.g., oversampling) or consolidate categories.

Key Insight: Income, Race, Grades are most influential in RF and bagging.


# 3. Regression: Predicting Cigarette Usage Days (CigaretteUsageDays)

# Prep

```{r}
rm(list = ls())   
load("youth_data.Rdata")
ls()
```

```{r}
head(df, 5)
```

```{r}
colnames(df)
```




```{r}
target <- "CigaretteUsageDays"
df <- df %>% rename(CigaretteUsageDays = IRCIGFM)
```

```{r}
predictors <- c(
  "ParentsSmoke",
  "PhysicalFights",
  "StolenItems", 
  "FriendsSmoke",  
  "PovertyLevel" 
)
```

```{r}
df <- df %>% rename(
  FriendsSmoke = FRDPCIG2,
  ParentsSmoke = PRPKCIG2,
  StolenItems = YOSTOLE2,
  PovertyLevel = POVERTY3,
  PhysicalFights = YOFIGHT2
)
```

```{r}
df$CigaretteUsageDays <- as.numeric(df$CigaretteUsageDays)
```

```{r}
predictors <- c("FriendsSmoke", "ParentsSmoke", "PhysicalFights", "StolenItems", "PovertyLevel")
target <- "CigaretteUsageDays"
```


```{r}
clean_df <- na.omit(df[, c(target, predictors)])

# Here, I have converted the target variable to numeric as I was earlier facing issue without it for further regression modeling.
clean_df[[target]] <- as.numeric(clean_df[[target]])
```

```{r}
set.seed(1)
train <- createDataPartition(clean_df[[target]], p = 0.7, list = FALSE)
data.train <- clean_df[train, ]
data.test <- clean_df[-train, ]
```



# Decision Tree

```{r}
tree_model <- rpart(
  paste(target, "~", paste(predictors, collapse = "+")),
  data = data.train,
  method = "anova",
  control = rpart.control(cp = 0.01)
)
# Anova used as method for regression
```


```{r}
tree_preds <- predict(tree_model, data.test)
tree_mse <- mean((tree_preds - data.test$CigaretteUsageDays)^2)
```


```{r}
print(paste("Decision Tree Test MSE:", tree_mse))
```

Comments:
Decision Tree (Anova with cp=0.01)
Performance: MSE: 125.32, RMSE: 11.19.
Simple splits based on ParentsSmoke and FriendsSmoke.


# Bagging


```{r}
bag_model <- randomForest(
  x = data.train[, predictors],
  y = data.train[, target],
  mtry = 5,
  ntree = 500,
  importance = TRUE
)
```

```{r}
bag_preds <- predict(bag_model, data.test[, predictors])
```


```{r}
bag_mse <- mean(((bag_preds) - (data.test$CigaretteUsageDays))^2)
print(paste("Bagging Test MSE:", bag_mse))
```

```{r}
print(importance(bag_model))
```

Comments:
Bagging (mtry=5)
Performance: MSE: 125.94 (slightly worse than decision tree).

Variable Importance:

PovertyLevel had the highest node purity.


# Random Forest

```{r}
rf_model <- randomForest(
  x = data.train[, predictors],
  y = data.train[, target],
  mtry = 5/3,  # p/3 for regression and RF
  ntree = 500,
  importance = TRUE
)
```


```{r}
rf_preds <- predict(rf_model, data.test[, predictors])
rf_mse <- mean((rf_preds - data.test$CigaretteUsageDays)^2)
```


```{r}
print(paste("Random Forest Test MSE:", rf_mse))
```


```{r}
print(importance(rf_model))
```

```{r}
plot(data.test$CigaretteUsageDays, rf_preds, 
     xlab = "Actual Days", ylab = "Predicted Days",
     main = "Actual vs. Predicted Cigarette Use (RF)")
abline(0, 1, col = "brown")
```

Comments:

Random Forest (mtry=5/3, almost 1)
Best Model as MSE: 123.84 (is lowest).
Variable Importance: Parents Smoke and Stolen Items most impactful.
For plot, points close to brown line = Accurate predictions.


# Boosting

```{r}
boost_model <- gbm(
  formula = as.formula(paste(target, "~", paste(predictors, collapse = "+"))),
  data = data.train,
  distribution = "gaussian",
  n.trees = 1000,
  interaction.depth = 4,
  shrinkage = 0.01,
  verbose = FALSE
)
```


```{r}
boost_preds <- predict(boost_model, data.test, n.trees = 1000)
boost_mse <- mean((boost_preds - data.test$CigaretteUsageDays)^2)
```


```{r}
print(paste("Boosting Test MSE:", boost_mse))
```

Trying on different shrinkage value and respective plot - trying similar to implementated in worksheet and practice In Class Work.

```{r}
lambdas <- c(0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 1)
train_mse <- c()
test_mse <- c()
```
Helps to loop through and get test, train MSE value to plot and find the best lambda value.
```{r}
for (lambda in lambdas) {
  set.seed(1)
  boost_model <- gbm(
    formula = as.formula(paste(target, "~", paste(predictors, collapse = "+"))),
    data = data.train,
    distribution = "gaussian",
    n.trees = 1000,
    shrinkage = lambda,
    interaction.depth = 4,
    verbose = FALSE
  )
  
  pred_train <- predict(boost_model, data.train, n.trees = 1000)
  train_mse <- c(train_mse, mean((pred_train - data.train[[target]])^2))

  pred_test <- predict(boost_model, data.test, n.trees = 1000)
  test_mse <- c(test_mse, mean((pred_test - data.test[[target]])^2))
}
```

```{r}
plot(lambdas, train_mse, type = "b", pch = 19, col = "darkblue",
     xlab = "Lambda values", ylab = "MSE",
     main = "Training MSE vs Shrinkage")
plot(lambdas, test_mse, type = "b", pch = 19, col = "darkred",
     xlab = "Lambda Values", ylab = "MSE", 
     main = "Test MSE vs Shrinkage")
```

```{r}
best_lambda <- lambdas[which.min(test_mse)]
cat("Optimal shrinkage parameter:", best_lambda, "\n")
```

```{r}
boost_model <- gbm(
  formula = as.formula(paste(target, "~", paste(predictors, collapse = "+"))),
  data = data.train,
  distribution = "gaussian",
  n.trees = 1000,
  shrinkage = best_lambda,
  interaction.depth = 4,
  verbose = FALSE
)
```

```{r}
# It will help me get the variable importance
print(summary(boost_model))
```

```{r}
library(pdp)
```

```{r}
partial_data <- partial(
  boost_model,
  pred.var = "ParentsSmoke",  # Top predictor -> replaced manually
  train = data.train,
  n.trees = 1000,
  type = "regression"
)
```
n.trees should be same as in training model.
```{r}
plotPartial(partial_data, main = "Effect of Parent's Smoking on Cigarette Use")
```

```{r}
plot(partial_data, 
     type = "l", 
     main = "Partial Dependence: Friends' Smoking Effect",
     xlab = "Number of Friends Who Smoke (FRDPCIG2)",
     ylab = "Predicted Cigarette Use Days",
     col = "gold",
     lwd = 2)
grid()
```

Insight:
Linear increase: More friends smoking -> Higher cigarette use.



Comments:

Boosting (GBM)
Optimal Lambda: 0.001.

Performance: MSE: 125.20 (close to decision tree).

Top Predictor: Parents Smoke has 28.55% relative influence.

Partial Dependence Plot: Linear increase in predicted use with higher Parents Smoke.



# Results Comparison

```{r}
results <- data.frame(
  Model = c("Decision Tree", "Bagging", "Random Forest", "Boosting"),
  MSE = c(tree_mse, bag_mse, rf_mse, boost_mse)
)

print(results)
```
```{r}
RMSE = sqrt(c(tree_mse, bag_mse, rf_mse, boost_mse))

results <- data.frame(
  Model = c("Decision Tree", "Bagging", "Random Forest", "Boosting"),
  RMSE = RMSE
)
results
```


```{r}
# Variable importance comparison
varImpCompare <- cbind(
  Bagging = importance(bag_model)[,1],
  RF = importance(rf_model)[,1],
  Boost = summary(boost_model)$rel.inf
)
```

Key Findings:
Top Predictors: Parents Smoke (28.6% rel. influence in boosting), with Stolen Items, Poverty Level.

Friend's smoking had a linear effect (more friends -> higher use).

Model Performance Comparison:

Model	MSE	RMSE
Decision Tree	125.32	11.19	
Bagging	125.94	11.22	
Random Forest	123.84	11.13	
Boosting	125.20	11.19

Key Insight:

Random Forest had the lowest MSE (123.84), making it the best regression model.

Boostingâ€™s partial dependence plots revealed parental smoking increased predicted use.
