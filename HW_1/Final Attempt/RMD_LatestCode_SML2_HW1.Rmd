---
author: "Hrishabh Kulkarni"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# List of Questions:
## Question 1. Binary Classification: Predict whether a youth has ever used marijuana (binary: Yes/No) based on demographics, youth experiences, and peer/parental influences?
## Question 2. Multi-Class Classification: How frequently do youths use alcohol (Seldom, Sometimes, Frequent) based on their social environment and demographics?
## Question 3. Regression: What is the best factors to predict the number of days a youth has used cigarettes in the past 30 days (continuous count)?


```{r}
library(rpart)
library(randomForest)
library(dplyr)
library(gbm)
library(caret)
library(pROC)
library(pdp)
library(rpart.plot)     # Using it for plotting decision trees
library(tree)
```



```{r}
rm(list = ls())   
load("youth_data.Rdata")
ls()
```

```{r}
head(df, 5)
```

```{r}
colnames(df)
```




## Question 1] Binary Classification: Predict whether a youth has ever used marijuana (binary: Yes/No) based on demographics, youth experiences, and peer/parental influences?


# Data Prep

```{r}
target_binary <- "MarijuanaUse"
df <- df %>% rename(MarijuanaUse = MRJFLAG)
```

```{r}
predictors_binary <- c(
  "ParentalDisapproval",
  "SchoolPunishment",  
  "GroupFights",         
  "Friends_Use_MJ",     
  "FriendsOfferedMJ",   
  "ParentsUseMJ"      
)
```

```{r}
df <- df %>% rename(
  FriendsUseMJ = FRDMEVR2,
  FriendsOfferedMJ = YFLTMRJ2,
  ParentsUseMJ = PRMJEVR2,
  ParentalDisapproval = PRMJMO,
  SchoolPunishment = STNDSMJ,
  GroupFights = YOGRPFT2
)
```


```{r}
# 1 = Used & 0 = Not Used
df$MarijuanaUse <- ifelse(df$MarijuanaUse == 1, 1, 0)
```


```{r}
predictors_binary <- c("FriendsUseMJ", "FriendsOfferedMJ", "ParentsUseMJ", "ParentalDisapproval", "SchoolPunishment", "GroupFights")
target_binary <- "MarijuanaUse"
```


```{r}
clean_df <- na.omit(df[, c(target_binary, predictors_binary)])


clean_df[[target_binary]] <- as.factor(clean_df[[target_binary]])
```

Above, I am converting target to factor, removes rows with NA's in the columns used for modeling.


```{r}
set.seed(1)
train <- createDataPartition(clean_df[[target_binary]], p = 0.7, list = FALSE)
data.train <- clean_df[train, ]
data.test <- clean_df[-train, ]
```

Used createDataPartition to split the data into training and testing sets.
It was the best way which was ensuring that the target variable is balanced in both sets.
Reference: https://www.rdocumentation.org/packages/caret/versions/6.0-94/topics/createDataPartition




# i) Decision Tree (With and Without Pruning)



```{r}
# Fitting unpruned tree
tree_unpruned <- rpart(
  paste(target_binary, "~", paste(predictors_binary, collapse = "+")),
  data = data.train,
  method = "class",
  control = rpart.control(cp = 0, minsplit = 10)
)
```

Made use of rpart library as it was easy to implement and I was facing continued issues with basic r code and cv.tree code.
rpart.control -> sets complexity parameter (cp) to 0 - means no pruning.
minsplit -> 10, means a node must have at least 10 observations to be split.
Reference: https://www.rdocumentation.org/packages/rpart/versions/4.1.24/topics/rpart

Unpruned Tree:
Deep and complex with many splits.
FriendsOfferedMJ and ParentalDisapproval are primary splits.
Accuracy: 87.99%.

```{r}
# Pruning tree
pruned_tree <- prune(tree_unpruned, cp = 0.01)
```

Pruned Tree (CP=0.01):
Simplified structure with fewer splits.
Accuracy: Similar to unpruned, but more interpretable and easy to understand and convey result.

```{r}
rpart.plot(tree_unpruned, main = "Unpruned Tree")
rpart.plot(pruned_tree, main = "Pruned Tree (CP=0.01)")
```

Using rpart.plot for better visualization of decision trees.
Reference: https://www.rdocumentation.org/packages/rpart.plot/versions/3.1.2/topics/rpart.plot

```{r}
plot(tree_unpruned, main="Unpruned Tree")
text(tree_unpruned, cex=0.5)

plot(pruned_tree, main="Pruned Tree (CP=0.01)")
text(pruned_tree, cex=1.5)
```
cex helped me to adjust the text size in the plot, so utilizing it for better visualization.

```{r}
tree_preds <- predict(tree_unpruned, data.test, type = "class")
```

```{r}
confusionMatrix(tree_preds, as.factor(data.test$MarijuanaUse))
```

```{r}
tree_probs  <- predict(tree_unpruned, data.test, type = "prob")[,2]
```


```{r}
get_class_metrics <- function(actual, pred_class, pred_prob = NULL, positive = "1") {
  cm        <- confusionMatrix(pred_class, actual, positive = positive)
  precision <- cm$byClass["Pos Pred Value"]
  recall    <- cm$byClass["Sensitivity"]
  f1        <- if (!is.na(precision) && !is.na(recall)) 2 * precision * recall / (precision + recall) else NA
  auc       <- if (!is.null(pred_prob))    as.numeric( pROC::auc( pROC::roc(actual, pred_prob) ) ) else NA
  data.frame(Precision = precision,
             Recall    = recall,
             F1        = f1,
             AUC       = auc,
             row.names = NULL)
}
```


```{r}
tree_metrics <- get_class_metrics(
  actual     = data.test$MarijuanaUse,
  pred_class = tree_preds,
  pred_prob  = tree_probs
)
```

```{r}
print(tree_metrics)
```
Pruning simplifies the tree but may sacrifice slight or no accuracy.




# ii) Bagging


```{r}
bag_binary <- randomForest(
  x = data.train[, predictors_binary],
  y = as.factor(data.train[, target_binary]),
  mtry = 6, # p -> bagging 
  ntree = 500,
  importance = TRUE
)
```


```{r}
varImpPlot(bag_binary, col = "blue", main = "Variable Importance (Alcohol Frequency)")
```

```{r}
bag_preds <- predict(bag_binary, data.test[, predictors_binary])
```


```{r}
confusionMatrix(bag_preds, as.factor(data.test$MarijuanaUse))
```

```{r}
bag_probs  <- predict(bag_binary, data.test[, predictors_binary], type = "prob")[,2]
```


```{r}
bag_metrics <- get_class_metrics(
  actual     = data.test$MarijuanaUse,
  pred_class = bag_preds,
  pred_prob  = bag_probs
)
```

```{r}
print(bag_metrics)
```

Bagging (mtry=6)
Variable Importance: SchoolPunishment and FriendsUseMJ most influential.

Performance:
Accuracy: 87.99% (same as decision tree).
OOB Error: 12.44% which tells moderate misclassification rate.




# iii) Random Forest


```{r}
rf_binary <- randomForest(
  x = data.train[, predictors_binary],
  y = as.factor(data.train[, target_binary]),
  mtry = sqrt(6),  # I am considering square root of p for classification
  ntree = 500,
  importance = TRUE
)
```

```{r}
print(rf_binary)
```

```{r}
varImpPlot(rf_binary, col = "orange", main = "Variable Importance (Alcohol Frequency)")
```

```{r}
rf_preds <- predict(rf_binary, data.test[, predictors_binary])
```


```{r}
confusionMatrix(rf_preds, as.factor(data.test$MarijuanaUse))
```

```{r}
rf_probs  <- predict(rf_binary, data.test[, predictors_binary], type = "prob")[,2]
```


```{r}
rf_metrics <- get_class_metrics(
  actual     = data.test$MarijuanaUse,
  pred_class = rf_preds,
  pred_prob  = rf_probs
)
```


```{r}
print(rf_metrics)
```


Random Forest (mtry=sqrt(6) almost equals 2)
Performance:
Accuracy: 87.86% 
slightly lower than bagging.
45.38% (struggled with identifying marijuana users.

Variable Importance:
Similar to bagging but with slight difference..


```{r}
# Implemented Test accuracy for different mtry values as performed in worksheet
test_acc <- c()
for (p in c(1, 3, 5, 7, 10)) {
  rf.temp <- randomForest(
    x = data.train[, predictors_binary],
    y = as.factor(data.train[, target_binary]),
    mtry = sqrt(p), 
    ntree = 500
  )
  pred <- predict(rf.temp, newdata = data.test[, predictors_binary])
  acc <- mean(pred == data.test$MarijuanaUse)
  test_acc <- c(test_acc, acc)
}

plot(c(1, 3, 5, 7, 10), test_acc, type = "b", pch = 19,
     xlab = "mtry Value", ylab = "Test Accuracy",
     main = "Test Accuracy vs mtry for MarijuanaUse RF")
```



# iv) Boosting


```{r}
table(data.train[[target_binary]])
```

```{r}
data.train[[target_binary]] <- as.integer(as.factor(data.train[[target_binary]])) - 1
```


```{r}
boost_binary <- gbm(
  formula = as.formula(paste(target_binary, "~", paste(predictors_binary, collapse = "+"))),
  data = data.train,
  distribution = "bernoulli",  # binary classification = bernoulli
  n.trees = 1000,
  interaction.depth = 4,
  shrinkage = 0.01,
  verbose = FALSE
)
```

```{r}
summary(boost_binary)
```
School Punishment is the most important predictor with 33.15% relative influence.

```{r}
gbm.perf(boost_binary)
```
350 iteration seems best.

ROC Curve (Boosting)

```{r}
boost_probs <- predict(boost_binary, data.test, n.trees = 1000, type = "response")
boost_preds <- ifelse(boost_probs > 0.5, 1, 0)
```

```{r}
roc_curve <- roc(data.test$MarijuanaUse, boost_probs)
plot(roc_curve, main = "ROC Curve (Boosting)", col = "brown")
```

Interpretation:
AUC > 0.9 indicates excellent model performance.


```{r}
confusionMatrix(as.factor(boost_preds), as.factor(data.test$MarijuanaUse))
```

Boosting (GBM)
Best Performance:
AUC > 0.9 -> accurate divisions.

Accuracy: 87.86% 
similar to RF but better class separation.
Other metric calculation for boosting was not possible as it was not working with the code I had implemented.
Error faced was due to the levels not matching.

Top Predictor:
School Punishment with 33.15% relative influence.

ROC Curve:
Strong true positive rate (sensitivity) vs. false positive rate.



Results Summary

Key Insight: 
Top Predictors:
School Punishment, Friends Use MJ, Friends Offered MJ (highest importance in boosting).
Parental disapproval and peer influence significantly impact marijuana use.

Model Comparison:

-> Decision Tree:
Accuracy : 0.8799
Precision: 0.6586826
Recall: 0.4731183
F1: 0.5506884
AUC: 0.8506544

-> Bagging:
Accuracy : 0.8799
Precision: 0.6596386
Recall: 0.4709677
F1: 0.5495609
AUC: 0.7529306

-> Random Forest:
Accuracy : 0.8786
Precision: 0.659375	 
Recall: 0.4537634	
F1: 0.5375796	
AUC: 0.8251563	
OOB estimate of  error rate: 12.44%

-> Boosting:
Accuracy : 0.8786 








## Question 2] Multi-Class Classification: How frequently do youths use alcohol (Seldom, Sometimes, Frequent) based on their social environment and demographics?


# Data Prep

```{r}
target_multi <- "AlcoholDays"
df <- df %>% rename(AlcoholDays = ALCYDAYS)
```

```{r}
df <- df %>%
  mutate(AlcoholDays = case_when(
    AlcoholDays %in% c(1,2) ~ 0, # Seldom
    AlcoholDays == 3      ~ 1,         # Sometimes/ Not Frequent
    AlcoholDays %in% c(4,5) ~ 2, # Frequent
    TRUE              ~ NA_real_
  ))
```

```{r}
predictors_multi <- c(
  "Grades", 
  "PhysicalFights",  
  "Gender",      
  "Race",       
  "Income",     
  "SchoolSafety" 
)
```

```{r}
df <- df %>% rename(
  Gender = IRSEX,
  Race = NEWRACE2,
  Income = INCOME,
  Grades = AVGGRADE,
  SchoolSafety = SCHFELT,
  PhysicalFights = YOFIGHT2
)
```

```{r}
df$AlcoholDays <- factor(df$AlcoholDays, levels = c(0,1,2))
```
Helps lock the factor levels for target variable, ensuring consistent levels across training and testing sets. Implemented several times throughout the code.
Refernce: https://stackoverflow.com/questions/39543606/r-getting-column-of-dataframe-from-string/39543627#39543627

```{r}
predictors_multi <- c("Gender", "Race", "Income", "Grades", "SchoolSafety", "PhysicalFights")
target_multi <- "AlcoholDays"
```

```{r}
clean_df <- na.omit(df[, c(target_multi, predictors_multi)])


clean_df[[target_multi]] <- as.factor(clean_df[[target_multi]])
```


```{r}
set.seed(1)
train <- createDataPartition(clean_df[[target_multi]], p = 0.7, list = FALSE)
data.train <- clean_df[train, ]
data.test <- clean_df[-train, ]
```




# i) Decision Tree

```{r}
#By default a Pruned tree as well as considering cp as 0.01
tree_multi <- rpart(
  paste(target_multi, "~", paste(predictors_multi, collapse = "+")),
  data = data.train,
  method = "class",
  control = rpart.control(cp = 0.01)
)
```

```{r}
print(tree_multi)
```

```{r}
printcp(tree_multi)
plotcp(tree_multi)
```
As, we can see that the cp has a very tight value and hence its not splitting at all.
To resolve this issue, I will now make the parameters more flexible and check if it splits the tree somehow.
plot.rpart() never draws a tree if the tree never splits.

```{r}
tree_multi <- rpart(
  paste(target_multi, "~", paste(predictors_multi, collapse = "+")),
  data = data.train,
  method = "class",
  control = rpart.control(cp = 0.001, minsplit = 10)
)
```

```{r}
plot(tree_multi, uniform = TRUE, margin = 0.1)
text(tree_multi, use.n = TRUE, cex = 0.7)
```
Now, it splits properly.


```{r}
tree_preds <- predict(tree_multi, data.test, type = "class")
```


```{r}
confusionMatrix(tree_preds, data.test$AlcoholDays)
```

Decision Tree (Pruned, CP=0.001)

```{r}
cm        <- table(data.test$AlcoholDays, tree_preds)
prec_cls  <- diag(cm) / colSums(cm)
rec_cls   <- diag(cm) / rowSums(cm)
f1_cls    <- 2 * prec_cls * rec_cls / (prec_cls + rec_cls)
```


```{r}
multi_metrics <- data.frame(
  Metric = c("Precision","Recall"," F1"),
  Macro  = c(mean(prec_cls, na.rm=TRUE),
             mean(rec_cls,  na.rm=TRUE),
             mean(f1_cls,   na.rm=TRUE))
)
```


```{r}
print(multi_metrics)
```


# ii) Bagging

```{r}
# Written this line as the unused factors were creating an issue so found a way to drop unused factor levels.
data.train[[target_multi]] <- droplevels(data.train[[target_multi]])

bag_multi <- randomForest(
  x = data.train[, predictors_multi],
  y = data.train[[target_multi]],
   mtry = 6,
  ntree = 500,
  importance = TRUE
)
```

```{r}
varImpPlot(bag_multi, col = "darkgreen", main = "Variable Importance (Alcohol Days)")
```

```{r}
print(bag_multi)
```

```{r}
bag_preds <- predict(bag_multi, data.test)
```


```{r}
# Again, this line helps maintaining the levels while&after predictions
bag_preds <- factor(bag_preds, levels = levels(data.test$AlcoholDays))
```

```{r}
confusionMatrix(bag_preds, data.test$AlcoholDays)
```

```{r}
cm        <- table(data.test$AlcoholDays, tree_preds)
prec_cls  <- diag(cm) / colSums(cm)
rec_cls   <- diag(cm) / rowSums(cm)
f1_cls    <- 2 * prec_cls * rec_cls / (prec_cls + rec_cls)
```


```{r}
multi_metrics <- data.frame(
  Metric = c("Precision","Recall"," F1"),
  Macro  = c(mean(prec_cls, na.rm=TRUE),
             mean(rec_cls,  na.rm=TRUE),
             mean(f1_cls,   na.rm=TRUE))
)
```


```{r}
print(multi_metrics)
```

Bagging (mtry=6)
Performance:
Accuracy: 
OOB Error: 
Variable Importance: Income, Race, and Grades most influential.


# iii) Random Forest

```{r}
rf_multi <- randomForest(
  x = data.train[, predictors_multi],
  y = data.train$AlcoholDays,
  mtry = sqrt(6),
  ntree = 500,
  importance = TRUE
)
```


```{r}
varImpPlot(rf_multi, col = "darkred", main = "Variable Importance (Alcohol Days)")
```

```{r}
print(rf_multi)
```

```{r}
rf_preds <- predict(rf_multi, data.test)
```

```{r}
rf_preds <- factor(rf_preds, levels = levels(data.test$AlcoholDays))
```

```{r}
confusionMatrix(rf_preds, data.test$AlcoholDays)
```

```{r}
cm        <- table(data.test$AlcoholDays, tree_preds)
prec_cls  <- diag(cm) / colSums(cm)
rec_cls   <- diag(cm) / rowSums(cm)
f1_cls    <- 2 * prec_cls * rec_cls / (prec_cls + rec_cls)
```


```{r}
multi_metrics <- data.frame(
  Metric = c("Precision","Recall"," F1"),
  Macro  = c(mean(prec_cls, na.rm=TRUE),
             mean(rec_cls,  na.rm=TRUE),
             mean(f1_cls,   na.rm=TRUE))
)
```


```{r}
print(multi_metrics)
```


Random Forest (mtry= sqrt(6) = almost 2)

Result Summary:
Top Predictors: Income, Race, Grades (most influential in RF/bagging).
School safety and gender had moderate effects.

Model Performance Comparison:

-> Decision Tree:
Accuracy : 0.8315
Precision: 0.4269231
Recall: 0.3238512
F1: 0.9089048

-> Bagging:
Accuracy : 0.8371
Precision: 0.4269231
Recall: 0.3238512
F1: 0.9089048
OOB estimate of  error rate: 16.27%

-> Random Forest:
Accuracy : 0.8558
Precision: 0.4269231	 
Recall: 0.3238512	
F1: 0.9089048	
OOB estimate of  error rate: 14.99%


Key Insight: Income, Race, Grades are most influential in RF and bagging.








# Question 3] Regression: What is the best factors to predict the number of days a youth has used cigarettes in the past 30 days (continuous count)?




# Data Prep

```{r}
rm(list = ls())   
load("youth_data.Rdata")
ls()
```

```{r}
head(df, 5)
```

```{r}
colnames(df)
```




```{r}
target <- "CigaretteUsageDays"
df <- df %>% rename(CigaretteUsageDays = IRCIGFM)
```

```{r}
predictors <- c(
  "ParentsSmoke",
  "PhysicalFights",
  "StolenItems", 
  "FriendsSmoke",  
  "PovertyLevel" 
)
```

```{r}
df <- df %>% rename(
  FriendsSmoke = FRDPCIG2,
  ParentsSmoke = PRPKCIG2,
  StolenItems = YOSTOLE2,
  PovertyLevel = POVERTY3,
  PhysicalFights = YOFIGHT2
)
```

```{r}
df$CigaretteUsageDays <- as.numeric(df$CigaretteUsageDays)
```

```{r}
predictors <- c("FriendsSmoke", "ParentsSmoke", "PhysicalFights", "StolenItems", "PovertyLevel")
target <- "CigaretteUsageDays"
```


```{r}
clean_df <- na.omit(df[, c(target, predictors)])

# Here, I have converted the target variable to numeric as I was earlier facing issue without it for further regression modeling.
clean_df[[target]] <- as.numeric(clean_df[[target]])
```

```{r}
set.seed(1)
train <- createDataPartition(clean_df[[target]], p = 0.7, list = FALSE)
data.train <- clean_df[train, ]
data.test <- clean_df[-train, ]
```



# i) Decision Tree

```{r}
tree_model <- rpart(
  paste(target, "~", paste(predictors, collapse = "+")),
  data = data.train,
  method = "anova",
  control = rpart.control(cp = 0.01)
)
# Anova used as method for regression
```


```{r}
tree_preds <- predict(tree_model, data.test)
tree_mse <- mean((tree_preds - data.test$CigaretteUsageDays)^2)
```


```{r}
print(paste("Decision Tree Test MSE:", tree_mse))
```
```{r}
# for regression
get_reg_metrics <- function(actual, pred) {
  mse  <- mean((pred - actual)^2)
  rmse <- sqrt(mse)
  mae  <- mean(abs(pred - actual))
  r2   <- cor(pred, actual)^2
  data.frame(MSE  = mse,
             RMSE = rmse,
             MAE  = mae,
             R2   = r2,
             row.names = NULL)
}
```

```{r}
tree_metrics   <- get_reg_metrics(
  actual = data.test$CigaretteUsageDays,
  pred   = tree_preds
)
```

```{r}
print(tree_metrics)
```

Comments:
Decision Tree (Anova with cp=0.01)
Performance: MSE: 125.32, RMSE: 11.19.
Simple splits based on ParentsSmoke and FriendsSmoke.


# ii) Bagging


```{r}
bag_model <- randomForest(
  x = data.train[, predictors],
  y = data.train[, target],
  mtry = 5,
  ntree = 500,
  importance = TRUE
)
```

```{r}
bag_preds <- predict(bag_model, data.test[, predictors])
```


```{r}
bag_mse <- mean(((bag_preds) - (data.test$CigaretteUsageDays))^2)
print(paste("Bagging Test MSE:", bag_mse))
```

```{r}
bag_preds     <- predict(bag_model, data.test[,predictors])
bag_metrics   <- get_reg_metrics(
  actual = data.test$CigaretteUsageDays,
  pred   = bag_preds
)
```

```{r}
print(bag_metrics)
```

```{r}
print(importance(bag_model))
```

Comments:
Bagging (mtry=5)
Performance: MSE: 125.94 (slightly worse than decision tree).

Variable Importance: PovertyLevel had the highest node purity.



# iii) Random Forest

```{r}
rf_model <- randomForest(
  x = data.train[, predictors],
  y = data.train[, target],
  mtry = 5/3,  # p/3 for regression and RF
  ntree = 500,
  importance = TRUE
)
```


```{r}
rf_preds <- predict(rf_model, data.test[, predictors])
rf_mse <- mean((rf_preds - data.test$CigaretteUsageDays)^2)
```


```{r}
print(paste("Random Forest Test MSE:", rf_mse))
```


```{r}
rf_metrics   <- get_reg_metrics(
  actual = data.test$CigaretteUsageDays,
  pred   = rf_preds
)
```

```{r}
print(rf_metrics)
```


```{r}
print(importance(rf_model))
```

```{r}
plot(data.test$CigaretteUsageDays, rf_preds, 
     xlab = "Actual Days", ylab = "Predicted Days",
     main = "Actual vs. Predicted Cigarette Use (RF)")
abline(0, 1, col = "brown")
```

Comments:

Random Forest (mtry=5/3, almost 1)
Best Model as MSE: 123.84 (is lowest).
Variable Importance: Parents Smoke and Stolen Items most impactful.
For plot, points close to brown line = Accurate predictions.




# iv) Boosting

```{r}
boost_model <- gbm(
  formula = as.formula(paste(target, "~", paste(predictors, collapse = "+"))),
  data = data.train,
  distribution = "gaussian",
  n.trees = 1000,
  interaction.depth = 4,
  shrinkage = 0.01,
  verbose = FALSE
)
```


```{r}
boost_preds <- predict(boost_model, data.test, n.trees = 1000)
boost_mse <- mean((boost_preds - data.test$CigaretteUsageDays)^2)
```


```{r}
print(paste("Boosting Test MSE:", boost_mse))
```

Trying on different shrinkage value and respective plot - trying similar to implementated in worksheet and practice In Class Work.

```{r}
lambdas <- c(0.001, 0.01, 0.05, 0.1, 0.2, 0.5, 1)
train_mse <- c()
test_mse <- c()
```

Helps to loop through and get test, train MSE value to plot and find the best lambda value.

```{r}
for (lambda in lambdas) {
  set.seed(1)
  boost_model <- gbm(
    formula = as.formula(paste(target, "~", paste(predictors, collapse = "+"))),
    data = data.train,
    distribution = "gaussian",
    n.trees = 1000,
    shrinkage = lambda,
    interaction.depth = 4,
    verbose = FALSE
  )
  
  pred_train <- predict(boost_model, data.train, n.trees = 1000)
  train_mse <- c(train_mse, mean((pred_train - data.train[[target]])^2))

  pred_test <- predict(boost_model, data.test, n.trees = 1000)
  test_mse <- c(test_mse, mean((pred_test - data.test[[target]])^2))
}
```

```{r}
bag_preds     <- predict(bag_model, data.test[,predictors])
bag_metrics   <- get_reg_metrics(
  actual = data.test$CigaretteUsageDays,
  pred   = bag_preds
)
print(bag_metrics)
```

```{r}
plot(lambdas, train_mse, type = "b", pch = 19, col = "darkblue",
     xlab = "Lambda values", ylab = "MSE",
     main = "Training MSE vs Shrinkage")
plot(lambdas, test_mse, type = "b", pch = 19, col = "darkred",
     xlab = "Lambda Values", ylab = "MSE", 
     main = "Test MSE vs Shrinkage")
```

```{r}
best_lambda <- lambdas[which.min(test_mse)]
cat("Optimal shrinkage parameter:", best_lambda, "\n")
```

```{r}
boost_model <- gbm(
  formula = as.formula(paste(target, "~", paste(predictors, collapse = "+"))),
  data = data.train,
  distribution = "gaussian",
  n.trees = 1000,
  shrinkage = best_lambda,
  interaction.depth = 4,
  verbose = FALSE
)
```

```{r}
# It will help me get the variable importance
print(summary(boost_model))
```

```{r}
library(pdp)
```

```{r}
partial_data <- partial(
  boost_model,
  pred.var = "ParentsSmoke",  # Top predictor -> replaced manually
  train = data.train,
  n.trees = 1000,
  type = "regression"
)
```
n.trees should be same as in training model.
```{r}
plotPartial(partial_data, main = "Effect of Parent's Smoking on Cigarette Use")
```

```{r}
plot(partial_data, 
     type = "l", 
     main = "Partial Dependence: Friends' Smoking Effect",
     xlab = "Number of Friends Who Smoke (FRDPCIG2)",
     ylab = "Predicted Cigarette Use Days",
     col = "gold",
     lwd = 2)
grid()
```

Insight:
Linear increase: More friends smoking -> Higher cigarette use.



Comments:

Boosting (GBM)
Optimal Lambda: 0.001.

Performance: MSE: 125.20 (close to decision tree).

Top Predictor: Parents Smoke has 28.55% relative influence.

Partial Dependence Plot: Linear increase in predicted use with higher Parents Smoke.



# Results Comparison

```{r}
results <- data.frame(
  Model = c("Decision Tree", "Bagging", "Random Forest", "Boosting"),
  MSE = c(tree_mse, bag_mse, rf_mse, boost_mse)
)

print(results)
```
```{r}
RMSE = sqrt(c(tree_mse, bag_mse, rf_mse, boost_mse))

results <- data.frame(
  Model = c("Decision Tree", "Bagging", "Random Forest", "Boosting"),
  RMSE = RMSE
)
results
```


```{r}
# Variable importance comparison
varImpCompare <- cbind(
  Bagging = importance(bag_model)[,1],
  RF = importance(rf_model)[,1],
  Boost = summary(boost_model)$rel.inf
)
```

Key Findings:
Top Predictors: Parents Smoke (28.6% rel. influence in boosting), with Stolen Items, Poverty Level.

Friend's smoking had a linear effect (more friends -> higher use).

Model Performance Comparison:

-> Decision Tree:
MSE: 125.3232
RMSE: 11.19479	
MAE: 2.457361
R^2: 0.008826548

-> Bagging:
MSE: 125.9376
RMSE: 11.22219
MAE: 2.44336
R^2: 0.01202626

-> Random Forest:
MSE: 123.8401
RMSE: 11.12835
MAE: 2.412055
R^2: 0.02081367

-> Boosting:
MSE: 125.9376
RMSE: 11.22219
MAE: 2.44336
R^2: 0.01202626


Key Insight:

Random Forest had the lowest MSE (123.84), making it the best regression model.

Boostingâ€™s partial dependence plots revealed parental smoking increased predicted use.
